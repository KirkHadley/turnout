{
 "metadata": {
  "name": "",
  "signature": "sha256:09478f61cb54b086b33b56f008ed3429d49693787da5906d72e72e6a62d8556f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Predicting Individual Level Turnout"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ignore this code, it's messiness"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import numpy as np\n",
      "import operator\n",
      "import pandas as pd\n",
      "from sklearn.hmm import GaussianHMM\n",
      "from multiprocessing import Pool\n",
      "import pickle\n",
      "from math import floor\n",
      "from sklearn.preprocessing import normalize\n",
      "\n",
      "a = ['vh00p1binary_plus_registration',\n",
      " 'vh00g1binary_plus_registration',\n",
      " 'vh02p1binary_plus_registration',\n",
      " 'vh02g1binary_plus_registration',\n",
      " 'vh04p1binary_plus_registration',\n",
      " 'vh04g1binary_plus_registration',\n",
      " 'vh06p1binary_plus_registration',\n",
      " 'vh06g1binary_plus_registration',\n",
      " 'vh08p1binary_plus_registration',\n",
      " 'vh08g1binary_plus_registration',\n",
      " 'vh10p1binary_plus_registration',\n",
      " 'vh10g1binary_plus_registration',\n",
      " 'vh12p1binary_plus_registration',\n",
      " 'vh12g1binary_plus_registration',\n",
      " 'vh00p1__method',\n",
      " 'vh00g1__method',\n",
      " 'vh02p1__method',\n",
      " 'vh02g1__method',\n",
      " 'vh04p1__method',\n",
      " 'vh04g1__method',\n",
      " 'vh06p1__method',\n",
      " 'vh06g1__method',\n",
      " 'vh08p1__method',\n",
      " 'vh08g1__method',\n",
      " 'vh10p1__method',\n",
      " 'vh10g1__method',\n",
      " 'vh12p1__method',\n",
      " 'vh12g1__method',\n",
      " 'vh00p1party',\n",
      " 'vh00g1party',\n",
      " 'vh02p1party',\n",
      " 'vh02g1party',\n",
      " 'vh04p1party',\n",
      " 'vh04g1party',\n",
      " 'vh06p1party',\n",
      " 'vh06g1party',\n",
      " 'vh08p1party',\n",
      " 'vh08g1party',\n",
      " 'vh10p1party',\n",
      " 'vh10g1party',\n",
      " 'vh12p1party',\n",
      " 'vh12g1party']\n",
      "\n",
      "raw_seq = pd.read_csv('testing.csv', usecols = a)\n",
      "comp = [8.65,8.65,12.125,12.125,7.1125,7.1125,7.76666666666667,7.76666666666667,9.5,9.5,4.2,4.2,4.83333333333333,4.83333333333333]\n",
      "comp = np.split(np.array(comp), 14)\n",
      "\n",
      "raw_seq = raw_seq[sorted(raw_seq.columns)]\n",
      "b = map(lambda x: np.split(x, 14), raw_seq.values)\n",
      "data = map(lambda x: np.column_stack([x, comp]), b)\n",
      "\n",
      "df = pd.read_csv('test.csv')\n",
      "clean_df = pd.read_csv('testing.csv')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/utils/sparsetools/__init__.py:3: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._min_spanning_tree import minimum_spanning_tree\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/utils/sparsetools/_graph_validation.py:5: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._graph_tools import csgraph_to_dense, csgraph_from_dense,\\\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/utils/sparsetools/__init__.py:4: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._traversal import connected_components\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/utils/extmath.py:20: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/utils/extmath.py:22: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .sparsefuncs_fast import csr_row_norms\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/scipy/spatial/__init__.py:90: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .ckdtree import *\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/scipy/spatial/__init__.py:91: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .qhull import *\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/scipy/stats/_continuous_distns.py:24: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from . import vonmises_cython\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/scipy/stats/stats.py:188: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._rank import rankdata, tiecorrect\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/metrics/cluster/supervised.py:18: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .expected_mutual_info_fast import expected_mutual_information\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/metrics/pairwise.py:56: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .ball_tree import BallTree\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/neighbors/__init__.py:7: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .kd_tree import KDTree\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/utils/graph.py:16: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .graph_shortest_path import graph_shortest_path\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/scipy/interpolate/interpolate.py:28: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from . import _ppoly\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/linear_model/least_angle.py:24: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ..utils import array2d, arrayfuncs, as_float_array, check_arrays\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:26: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from . import cd_fast\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/linear_model/__init__.py:21: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from . import libsvm, liblinear\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/svm/base.py:9: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from . import libsvm_sparse\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/utils/random.py:9: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._random import sample_without_replacement\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/isotonic.py:11: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from ._isotonic import _isotonic_regression\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/manifold/t_sne.py:21: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from . import _utils\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:34: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from . import _k_means\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:24: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from . import _hierarchical\n",
        "/home/kirk/DSgeneralEnv/local/lib/python2.7/site-packages/sklearn/hmm.py:28: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from . import _hmmc\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The problem of predicting individual-level voter behavior (i.e. the notion of predicting exactly what course of action person X will take on the Tuesday after the first Monday in November) presents several statistical challenges, each of which is handled by the novel model described herein. I will be demonstrating the specific workings of my model by showing each step being applied to a sample of the Colorado voter file. \n",
      "<br>\n",
      "I consider the challenges found in this sort of prediction task to be the following:\n",
      "\n",
      "1. How do we combine static and sequential data?\n",
      "2. How do we predict regime change?\n",
      "3. How do we account for factors that are unique to each election?\n",
      "4. How do we handle missing data?\n",
      "5. How do we model processes that violate most traditional statistical assumptions (i.e. linearity, stationarity, homogeneity, etc.)\n",
      "6. How do we predict something we can't really see?\n",
      "1. As in we want to predict if you're planning to vote, not so much your specific day of behaviors. Some foresight would be ideal\n",
      "7. How do we do this in a probabilistic fashion (i.e. it would be nice to not just predict \u201cyes\u201d, but a \u201cstrong yes\u201d or a \u201cweak yes\u201d as well).\n",
      "<br>\n",
      "However, before we can begin to do any predictive modeling, we first need to do some data cleaning. \n",
      "<br>\n",
      "Our data set begins like this:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>nbec_guid</th>\n",
        "      <th>state_file_id</th>\n",
        "      <th>county_file_id</th>\n",
        "      <th>state</th>\n",
        "      <th>fips</th>\n",
        "      <th>prefix</th>\n",
        "      <th>first_name</th>\n",
        "      <th>middle_name</th>\n",
        "      <th>last_name</th>\n",
        "      <th>suffix</th>\n",
        "      <th>...</th>\n",
        "      <th>vh12pp1</th>\n",
        "      <th>vh13p1</th>\n",
        "      <th>vh13g1</th>\n",
        "      <th>vh14p1</th>\n",
        "      <th>vh14g1</th>\n",
        "      <th>vh15p1</th>\n",
        "      <th>vh15g1</th>\n",
        "      <th>vh16p1</th>\n",
        "      <th>vh16g1</th>\n",
        "      <th>vh16pp1</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 9a7375ec-00f6-11e2-b4a6-8f0d0e01d7ab</td>\n",
        "      <td> 200171691</td>\n",
        "      <td>NaN</td>\n",
        "      <td> CO</td>\n",
        "      <td> 8031</td>\n",
        "      <td>NaN</td>\n",
        "      <td> Jessica</td>\n",
        "      <td>  Leigh</td>\n",
        "      <td>     Schell</td>\n",
        "      <td> NaN</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 9a0b228a-00f6-11e2-804b-ffdc26c69b79</td>\n",
        "      <td>    299535</td>\n",
        "      <td>NaN</td>\n",
        "      <td> CO</td>\n",
        "      <td> 8031</td>\n",
        "      <td>NaN</td>\n",
        "      <td> Brandon</td>\n",
        "      <td>   Mark</td>\n",
        "      <td> Rodighiero</td>\n",
        "      <td> NaN</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 9cb09df8-00f6-11e2-b259-2b6f2ace4fc4</td>\n",
        "      <td>   2742127</td>\n",
        "      <td>NaN</td>\n",
        "      <td> CO</td>\n",
        "      <td> 8031</td>\n",
        "      <td>NaN</td>\n",
        "      <td>   Amber</td>\n",
        "      <td> Nicole</td>\n",
        "      <td>   Northrop</td>\n",
        "      <td> NaN</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> afbb1ee6-00f6-11e2-826a-07e67ab69e9c</td>\n",
        "      <td>   2609956</td>\n",
        "      <td>NaN</td>\n",
        "      <td> CO</td>\n",
        "      <td> 8031</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  Melvin</td>\n",
        "      <td>    Ace</td>\n",
        "      <td>     Mchone</td>\n",
        "      <td>  II</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> d52477cc-00f6-11e2-9b2e-6fd763728428</td>\n",
        "      <td>   2644410</td>\n",
        "      <td>NaN</td>\n",
        "      <td> CO</td>\n",
        "      <td> 8059</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  Roland</td>\n",
        "      <td> Dougie</td>\n",
        "      <td>     Reeves</td>\n",
        "      <td> NaN</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  2</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 87 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "                              nbec_guid  state_file_id  county_file_id state  \\\n",
        "0  9a7375ec-00f6-11e2-b4a6-8f0d0e01d7ab      200171691             NaN    CO   \n",
        "1  9a0b228a-00f6-11e2-804b-ffdc26c69b79         299535             NaN    CO   \n",
        "2  9cb09df8-00f6-11e2-b259-2b6f2ace4fc4        2742127             NaN    CO   \n",
        "3  afbb1ee6-00f6-11e2-826a-07e67ab69e9c        2609956             NaN    CO   \n",
        "4  d52477cc-00f6-11e2-9b2e-6fd763728428        2644410             NaN    CO   \n",
        "\n",
        "   fips  prefix first_name middle_name   last_name suffix  ...   vh12pp1  \\\n",
        "0  8031     NaN    Jessica       Leigh      Schell    NaN  ...       NaN   \n",
        "1  8031     NaN    Brandon        Mark  Rodighiero    NaN  ...       NaN   \n",
        "2  8031     NaN      Amber      Nicole    Northrop    NaN  ...       NaN   \n",
        "3  8031     NaN     Melvin         Ace      Mchone     II  ...       NaN   \n",
        "4  8059     NaN     Roland      Dougie      Reeves    NaN  ...       NaN   \n",
        "\n",
        "  vh13p1 vh13g1 vh14p1 vh14g1 vh15p1 vh15g1  vh16p1  vh16g1 vh16pp1  \n",
        "0    NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN     NaN  \n",
        "1    NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN     NaN  \n",
        "2    NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN     NaN  \n",
        "3    NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN     NaN  \n",
        "4    NaN      2    NaN    NaN    NaN    NaN     NaN     NaN     NaN  \n",
        "\n",
        "[5 rows x 87 columns]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lots of messiness, lots of missing fields. Generally not useful. We transform it to look like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "clean_df[clean_df.columns[3:]].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>gender</th>\n",
        "      <th>born_at</th>\n",
        "      <th>demo</th>\n",
        "      <th>party</th>\n",
        "      <th>is_active_voter</th>\n",
        "      <th>is_perm_absentee</th>\n",
        "      <th>registered_at</th>\n",
        "      <th>is_do_not_call</th>\n",
        "      <th>residential_address2</th>\n",
        "      <th>residential_city</th>\n",
        "      <th>...</th>\n",
        "      <th>vh04p1_time_registered</th>\n",
        "      <th>vh04g1_time_registered</th>\n",
        "      <th>vh06p1_time_registered</th>\n",
        "      <th>vh06g1_time_registered</th>\n",
        "      <th>vh08p1_time_registered</th>\n",
        "      <th>vh08g1_time_registered</th>\n",
        "      <th>vh10p1_time_registered</th>\n",
        "      <th>vh10g1_time_registered</th>\n",
        "      <th>vh12p1_time_registered</th>\n",
        "      <th>vh12g1_time_registered</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> F</td>\n",
        "      <td> 1990-01-01</td>\n",
        "      <td> W</td>\n",
        "      <td> D</td>\n",
        "      <td> True</td>\n",
        "      <td> False</td>\n",
        "      <td> 2012-10-06 00:00:00</td>\n",
        "      <td>  True</td>\n",
        "      <td> Apt 539</td>\n",
        "      <td>   Denver</td>\n",
        "      <td>...</td>\n",
        "      <td> -2895 days, 00:00:00</td>\n",
        "      <td> -2895 days, 00:00:00</td>\n",
        "      <td> -2165 days, 00:00:00</td>\n",
        "      <td> -2165 days, 00:00:00</td>\n",
        "      <td> -1434 days, 00:00:00</td>\n",
        "      <td> -1434 days, 00:00:00</td>\n",
        "      <td> -704 days, 00:00:00</td>\n",
        "      <td> -704 days, 00:00:00</td>\n",
        "      <td>   27 days, 00:00:00</td>\n",
        "      <td>   27 days, 00:00:00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> M</td>\n",
        "      <td> 1985-01-01</td>\n",
        "      <td> O</td>\n",
        "      <td> D</td>\n",
        "      <td> True</td>\n",
        "      <td>  True</td>\n",
        "      <td> 2012-07-17 00:00:00</td>\n",
        "      <td> False</td>\n",
        "      <td> Apt 539</td>\n",
        "      <td>   Denver</td>\n",
        "      <td>...</td>\n",
        "      <td> -2814 days, 00:00:00</td>\n",
        "      <td> -2814 days, 00:00:00</td>\n",
        "      <td> -2084 days, 00:00:00</td>\n",
        "      <td> -2084 days, 00:00:00</td>\n",
        "      <td> -1353 days, 00:00:00</td>\n",
        "      <td> -1353 days, 00:00:00</td>\n",
        "      <td> -623 days, 00:00:00</td>\n",
        "      <td> -623 days, 00:00:00</td>\n",
        "      <td>  108 days, 00:00:00</td>\n",
        "      <td>  108 days, 00:00:00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> F</td>\n",
        "      <td> 1980-01-01</td>\n",
        "      <td> W</td>\n",
        "      <td> D</td>\n",
        "      <td> True</td>\n",
        "      <td> False</td>\n",
        "      <td> 2001-11-05 00:00:00</td>\n",
        "      <td> False</td>\n",
        "      <td>   Apt 1</td>\n",
        "      <td>   Denver</td>\n",
        "      <td>...</td>\n",
        "      <td>  1093 days, 00:00:00</td>\n",
        "      <td>  1093 days, 00:00:00</td>\n",
        "      <td>  1823 days, 00:00:00</td>\n",
        "      <td>  1823 days, 00:00:00</td>\n",
        "      <td>  2554 days, 00:00:00</td>\n",
        "      <td>  2554 days, 00:00:00</td>\n",
        "      <td> 3284 days, 00:00:00</td>\n",
        "      <td> 3284 days, 00:00:00</td>\n",
        "      <td> 4015 days, 00:00:00</td>\n",
        "      <td> 4015 days, 00:00:00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> M</td>\n",
        "      <td> 1935-01-01</td>\n",
        "      <td> W</td>\n",
        "      <td> D</td>\n",
        "      <td> True</td>\n",
        "      <td> False</td>\n",
        "      <td> 2003-12-17 00:00:00</td>\n",
        "      <td> False</td>\n",
        "      <td>  Apt 32</td>\n",
        "      <td>   Denver</td>\n",
        "      <td>...</td>\n",
        "      <td>   321 days, 00:00:00</td>\n",
        "      <td>   321 days, 00:00:00</td>\n",
        "      <td>  1051 days, 00:00:00</td>\n",
        "      <td>  1051 days, 00:00:00</td>\n",
        "      <td>  1782 days, 00:00:00</td>\n",
        "      <td>  1782 days, 00:00:00</td>\n",
        "      <td> 2512 days, 00:00:00</td>\n",
        "      <td> 2512 days, 00:00:00</td>\n",
        "      <td> 3243 days, 00:00:00</td>\n",
        "      <td> 3243 days, 00:00:00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> M</td>\n",
        "      <td> 1950-01-01</td>\n",
        "      <td> W</td>\n",
        "      <td> D</td>\n",
        "      <td> True</td>\n",
        "      <td>  True</td>\n",
        "      <td> 2011-06-08 00:00:00</td>\n",
        "      <td> False</td>\n",
        "      <td>    7130</td>\n",
        "      <td> Lakewood</td>\n",
        "      <td>...</td>\n",
        "      <td> -2409 days, 00:00:00</td>\n",
        "      <td> -2409 days, 00:00:00</td>\n",
        "      <td> -1679 days, 00:00:00</td>\n",
        "      <td> -1679 days, 00:00:00</td>\n",
        "      <td>  -948 days, 00:00:00</td>\n",
        "      <td>  -948 days, 00:00:00</td>\n",
        "      <td> -218 days, 00:00:00</td>\n",
        "      <td> -218 days, 00:00:00</td>\n",
        "      <td>  513 days, 00:00:00</td>\n",
        "      <td>  513 days, 00:00:00</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 84 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "  gender     born_at demo party is_active_voter is_perm_absentee  \\\n",
        "0      F  1990-01-01    W     D            True            False   \n",
        "1      M  1985-01-01    O     D            True             True   \n",
        "2      F  1980-01-01    W     D            True            False   \n",
        "3      M  1935-01-01    W     D            True            False   \n",
        "4      M  1950-01-01    W     D            True             True   \n",
        "\n",
        "         registered_at is_do_not_call residential_address2 residential_city  \\\n",
        "0  2012-10-06 00:00:00           True              Apt 539           Denver   \n",
        "1  2012-07-17 00:00:00          False              Apt 539           Denver   \n",
        "2  2001-11-05 00:00:00          False                Apt 1           Denver   \n",
        "3  2003-12-17 00:00:00          False               Apt 32           Denver   \n",
        "4  2011-06-08 00:00:00          False                 7130         Lakewood   \n",
        "\n",
        "        ...        vh04p1_time_registered  vh04g1_time_registered  \\\n",
        "0       ...          -2895 days, 00:00:00    -2895 days, 00:00:00   \n",
        "1       ...          -2814 days, 00:00:00    -2814 days, 00:00:00   \n",
        "2       ...           1093 days, 00:00:00     1093 days, 00:00:00   \n",
        "3       ...            321 days, 00:00:00      321 days, 00:00:00   \n",
        "4       ...          -2409 days, 00:00:00    -2409 days, 00:00:00   \n",
        "\n",
        "   vh06p1_time_registered vh06g1_time_registered  vh08p1_time_registered  \\\n",
        "0    -2165 days, 00:00:00   -2165 days, 00:00:00    -1434 days, 00:00:00   \n",
        "1    -2084 days, 00:00:00   -2084 days, 00:00:00    -1353 days, 00:00:00   \n",
        "2     1823 days, 00:00:00    1823 days, 00:00:00     2554 days, 00:00:00   \n",
        "3     1051 days, 00:00:00    1051 days, 00:00:00     1782 days, 00:00:00   \n",
        "4    -1679 days, 00:00:00   -1679 days, 00:00:00     -948 days, 00:00:00   \n",
        "\n",
        "   vh08g1_time_registered  vh10p1_time_registered  vh10g1_time_registered  \\\n",
        "0    -1434 days, 00:00:00     -704 days, 00:00:00     -704 days, 00:00:00   \n",
        "1    -1353 days, 00:00:00     -623 days, 00:00:00     -623 days, 00:00:00   \n",
        "2     2554 days, 00:00:00     3284 days, 00:00:00     3284 days, 00:00:00   \n",
        "3     1782 days, 00:00:00     2512 days, 00:00:00     2512 days, 00:00:00   \n",
        "4     -948 days, 00:00:00     -218 days, 00:00:00     -218 days, 00:00:00   \n",
        "\n",
        "   vh12p1_time_registered  vh12g1_time_registered  \n",
        "0       27 days, 00:00:00       27 days, 00:00:00  \n",
        "1      108 days, 00:00:00      108 days, 00:00:00  \n",
        "2     4015 days, 00:00:00     4015 days, 00:00:00  \n",
        "3     3243 days, 00:00:00     3243 days, 00:00:00  \n",
        "4      513 days, 00:00:00      513 days, 00:00:00  \n",
        "\n",
        "[5 rows x 84 columns]"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The problem with this data set, however, is that it still equates the sequential data (how a person voted in a particular year) with the static data (say their gender). As such, we apply another transformation to reflect the sequential nature of the data. Note that in the far right column I've added the average margin found from all the available polling data for a given district (where it's not available, I've averaged the closest districts and statewide races)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array([[ -1.        ,   0.        ,   0.        ,   8.65      ],\n",
        "       [ -1.        ,   0.        ,   0.        ,   8.65      ],\n",
        "       [ -1.        ,   0.        ,   0.        ,  12.125     ],\n",
        "       [ -1.        ,   0.        ,   0.        ,  12.125     ],\n",
        "       [ -1.        ,   0.        ,   0.        ,   7.1125    ],\n",
        "       [ -1.        ,   0.        ,   0.        ,   7.1125    ],\n",
        "       [ -1.        ,   0.        ,   0.        ,   7.76666667],\n",
        "       [ -1.        ,   0.        ,   0.        ,   7.76666667],\n",
        "       [  0.        ,   0.        ,   1.        ,   9.5       ],\n",
        "       [ -1.        ,   0.        ,   0.        ,   9.5       ],\n",
        "       [  0.        ,   0.        ,   1.        ,   4.2       ],\n",
        "       [ -1.        ,   0.        ,   0.        ,   4.2       ],\n",
        "       [ -1.        ,  -1.        ,   0.        ,   4.83333333],\n",
        "       [ -1.        ,  -1.        ,   0.        ,   4.83333333]])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And with that, we now have a clean data set. Cleanliness is next to godliness."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Step One: Voter Clustering with a Hidden Markov Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first step in the my model is to create a Hidden Markov Model, which, despite its ominous sounding name, is actually a fairly simple concept. Essentially what we do is calculate the probability of each individual's voting sequence. \n",
      "\n",
      "To be more specific, a Hidden Markov Model (HMM) assumes that any event in a sequence depends only on the event that immediately preceded it. In practice, this helps us solve a couple of the challenges that I outlined in the beginning. The HMM provides critical information to help solve challenges 1,2,3,5, and 6. The HMM helps with six because it's formulation is specifically designed to account for situations in which you can observe certain factors, but are really interested in calculating the probability of a factor you can't observe (as in, it's hidden). HMMs are quite common in medical research for calculating probabilities of event occurrences between doctor's visits.\n",
      "\n",
      "Now, once we've calculated the probabilities of these various sequences of events, we sort all our voters by the likelihood of their voting sequence. Once we sort them, we split them into even numbered groups, which we then pass to the next step of our model. What's the point of doing that? The idea is that, by clustering (breaking into similar groups) the voters, we'll be able to create models that only have to predict a similar set of patterns. That makes the math much friendlier.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "post_hmm = pd.read_csv('clean_test.csv')\n",
      "post_hmm['likelihood'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "0   -113.243358\n",
        "1   -109.369212\n",
        "2   -103.873729\n",
        "3   -103.745424\n",
        "4   -103.745424\n",
        "Name: likelihood, dtype: float64"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Neural Networks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Having clustered our voters into different groups, we can now begin to actually predict voter outcomes.   We'll be using two different artificial intelligence algorithms to detect patterns in this data and predict future events. Both of these algorithms fall under a broad umbrella of computational mathematics (close to statistics) called deep learning, which the NYT has written about [1]. Specifically, I applied two variations of deep learning methods, Recurrent Neural Networks (RNN) and Feed-Forward Neural Networks (FFNN). I'll spare you the mathematical notation and greek lettering, but the idea is to find the combination of variables that, when taken as a weighted average of sorts, best approximates the output values in question. Both the RNN and FFNN help to provide solutions to challenges 3,4,5, and 7. However, the two models differ in one very important way.\n",
      "\n",
      "RNN are designed to predict sequential data. The Recurrent part of their name refers to the ability to \u201cremember\u201d past events so as to identify connections between the past and present events, which it then applies to the work of predicting future outcomes. For this reason, the RNN uses the same data that we originally passed to the HMM. FFNN, on the other hand, deal exclusively with predicting future events using static data. As such, the FFNN learns patterns from the static data found in the cleaned up data set. Specifically, it uses party affiliation, gender, zip code, and median income by zip code to predict future voting behaviors.\n",
      "\n",
      "Neither the RNN or FFNN produce output that's easily human-readable, but their calculations are absolutely necessary for the next step in this process. \n",
      "\n",
      "[1] http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html?pagewanted=all&_r=0"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Bringing it All Together"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}